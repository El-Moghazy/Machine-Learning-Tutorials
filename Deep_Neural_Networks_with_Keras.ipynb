{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deep Neural Networks with Keras.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "eZsGESG14HEC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<h1>Deep Neural Networks with Keras</h1>\n",
        "In this tutorial I will explain how to classify the MNIST dataset using DNNs (Deep Neural Network). The code will be written using python with the help of Keras library which is a high level library and i am going to use TensorFlow as it's backend.\n",
        "\n",
        "  Now let's import Keras and some other useful libraries that we are gonna use later and also we will load the data from keras databases for later use."
      ]
    },
    {
      "metadata": {
        "id": "w3kXCMug4F9r",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4a650219-4f51-4b1b-c6a7-a1df72e9a124",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1530806450604,
          "user_tz": -120,
          "elapsed": 2263,
          "user": {
            "displayName": "Abd El Rhman ElMoghazy",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "112798608963931725749"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from keras.datasets import mnist\n",
        "import numpy as np\n",
        "np.random.seed(0)\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "RJcvQysl6xz2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<h1>Data Exploration</h1>\n",
        "Let's explore the data we have as this will give us a hint on the algorithm we will use if we have to choose. Exploring data is also very important because it will tell you which accuracy metric you are going to use, if the data is balanced which means all the classes have fair contribution in the dataset regarding its numbers then we can easily use accuracy, But if the data is skewed then we won't be able to use accurace as it's results will be misleading and we may use F-beta score instead."
      ]
    },
    {
      "metadata": {
        "id": "qISzguL479UT",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "1f0ac568-3933-4e80-8961-3bc2a949d503",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1530806452580,
          "user_tz": -120,
          "elapsed": 1944,
          "user": {
            "displayName": "Abd El Rhman ElMoghazy",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "112798608963931725749"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"the number of training examples = %i\" % x_train.shape[0])\n",
        "print(\"the number of classes = %i\" % len(np.unique(y_train)))\n",
        "print(\"Dimention of images = {:d} x {:d}  \".format(x_train[1].shape[0],x_train[1].shape[1])  )\n",
        "\n",
        "#This line will allow us to know the number of occurrences of each specific class in the data\n",
        "unique, count= np.unique(y_train, return_counts=True)\n",
        "print(\"The number of occuranc of each class in the dataset = %s \" % dict (zip(unique, count) ), \"\\n\" )\n",
        "\n",
        "#Normalizing the input dataset\n",
        "x_train = x_train / 255\n",
        "x_test = x_test / 255\n",
        " \n",
        "images_and_labels = list(zip(x_train,  y_train))\n",
        "for index, (image, label) in enumerate(images_and_labels[:12]):\n",
        "    plt.subplot(5, 4, index + 1)\n",
        "    plt.axis('off')\n",
        "    plt.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
        "    plt.title('label: %i' % label)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the number of training examples = 60000\n",
            "the number of classes = 10\n",
            "Dimention of images = 28 x 28  \n",
            "The number of occuranc of each class in the dataset = {0: 5923, 1: 6742, 2: 5958, 3: 6131, 4: 5842, 5: 5421, 6: 5918, 7: 6265, 8: 5851, 9: 5949}  \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbIAAADdCAYAAADepvcnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f3dd645e780>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "RSc6zzzPcI27",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "From the previous results we can see that the dataset consists of 60000 training example each is an image of dimention 28 * 28. We can see that the number of occurances of each class is almost balanced and based on that it is safe to use accuracy as our metric later."
      ]
    },
    {
      "metadata": {
        "id": "_L47xC5pc20Z",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<h1>Algorithm Choice</h1>\n",
        "In this tutorial we will use the Deep Neural Networks Algorithm. Deep Neural Networks consists of a building block called the neuron. Each neural network consists of levels and each level consists of neurons. A neuron in the NN layer outputs discrete values for a classification task so it even fires or doesn't fire.\n",
        "![Deep Neural Network example](https://raw.githubusercontent.com/MoghazyCoder/Machine-Learning-Tutorials/master/Deep.png)\n",
        "\n",
        "Neurons uses the equation that determines whether or not it will fire. each neuron outputs the result from applying the function a(z) where a() is the activation function and z is the linear function WX + b and passes it to the next layer neurons. One of the mostly used activation function is the Relu function that is because it solves the problem of the exploding gradient, You can read more about that [here](https://machinelearningmastery.com/exploding-gradients-in-neural-networks/)."
      ]
    },
    {
      "metadata": {
        "id": "FoBmtygovCSD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<h1>Parameter and Model Selection</h1>\n",
        "Now Let's fit the model. We will make a sequential model which is a stack of layers, each layer passes the output to the next layer. we must reshape the input data to make the image a 1d vector instead to be able to pass it to the Deep Neural Network."
      ]
    },
    {
      "metadata": {
        "id": "i6HEF4bXc2Wa",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "0d26835c-8797-4ae3-e72a-12e9d7dd00c4",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1530806453178,
          "user_tz": -120,
          "elapsed": 573,
          "user": {
            "displayName": "Abd El Rhman ElMoghazy",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "112798608963931725749"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.utils import np_utils\n",
        "\n",
        "#reshape the inputs\n",
        "x_train = x_train.reshape(-1, 784)\n",
        "x_test = x_test.reshape(-1, 784)\n",
        "\n",
        "print(x_train.shape )\n",
        "print(x_train.shape )\n",
        "\n",
        "\n",
        "#Makine the outputs 1-hot vector of 10 elements\n",
        "y_train = np_utils.to_categorical(y_train)\n",
        "y_test = np_utils.to_categorical(y_test)\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(units=1024, activation='relu', input_dim= 784 ) )\n",
        "model.add(Dense(units=1024, activation='relu' ))\n",
        "model.add(Dense(units=512, activation='relu'  ))\n",
        "model.add(Dense(units=512, activation='relu'  ))\n",
        "\n",
        "#and now the output layer which will have 10 units to\n",
        "#output a 1-hot vector to detect one of the 10 classes\n",
        "model.add(Dense(units=10, activation='softmax'))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 784)\n",
            "(60000, 784)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6aODoDld8kEN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let's configure the learning process and choose the suitable parameters.we will use [catagorical cross entropy as the loss finction](http://neuralnetworksanddeeplearning.com/chap3.html), adam optimizer which  is an efficient gradient descent algorithm that proved to work well and our performance metric will be the accuracy."
      ]
    },
    {
      "metadata": {
        "id": "0kpTIGDQ8qAh",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from keras import optimizers\n",
        "\n",
        "optimizer = optimizers.Adam(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.001)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GaXlA2t1lLKS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now it is time to train the Network. We will use an early stopping function to stp the training if the validation loss doesn't change with patience of 50 epochs"
      ]
    },
    {
      "metadata": {
        "id": "hTMbslue9uJ8",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 1108
        },
        "outputId": "975270ac-5071-4339-8f42-49d98238185e",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1530806582809,
          "user_tz": -120,
          "elapsed": 128991,
          "user": {
            "displayName": "Abd El Rhman ElMoghazy",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "112798608963931725749"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from keras import callbacks\n",
        "earlystopping = callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=50, verbose=0, mode='min')\n",
        "model.fit(x_train, y_train, epochs=30, batch_size=200, validation_split=0.2, verbose=1, callbacks=[earlystopping])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Variable *= will be deprecated. Use variable.assign_mul if you want assignment to the variable value or 'x = x * y' if you want a new python Tensor object.\n",
            "Train on 48000 samples, validate on 12000 samples\n",
            "Epoch 1/30\n",
            "48000/48000 [==============================] - 6s 119us/step - loss: 0.2443 - acc: 0.9240 - val_loss: 0.1284 - val_acc: 0.9641\n",
            "Epoch 2/30\n",
            "48000/48000 [==============================] - 4s 87us/step - loss: 0.0890 - acc: 0.9736 - val_loss: 0.1091 - val_acc: 0.9709\n",
            "Epoch 3/30\n",
            "48000/48000 [==============================] - 4s 89us/step - loss: 0.0521 - acc: 0.9847 - val_loss: 0.0910 - val_acc: 0.9728\n",
            "Epoch 4/30\n",
            " 5600/48000 [==>...........................] - ETA: 3s - loss: 0.0285 - acc: 0.9916"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "48000/48000 [==============================] - 4s 90us/step - loss: 0.0339 - acc: 0.9895 - val_loss: 0.1037 - val_acc: 0.9745\n",
            "Epoch 5/30\n",
            "48000/48000 [==============================] - 5s 94us/step - loss: 0.0270 - acc: 0.9916 - val_loss: 0.1038 - val_acc: 0.9749\n",
            "Epoch 6/30\n",
            "48000/48000 [==============================] - 4s 89us/step - loss: 0.0167 - acc: 0.9948 - val_loss: 0.0950 - val_acc: 0.9776\n",
            "Epoch 7/30\n",
            "48000/48000 [==============================] - 4s 91us/step - loss: 0.0136 - acc: 0.9962 - val_loss: 0.0939 - val_acc: 0.9798\n",
            "Epoch 8/30\n",
            "17200/48000 [=========>....................] - ETA: 2s - loss: 0.0081 - acc: 0.9976"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "48000/48000 [==============================] - 5s 94us/step - loss: 0.0109 - acc: 0.9964 - val_loss: 0.1062 - val_acc: 0.9777\n",
            "Epoch 9/30\n",
            "48000/48000 [==============================] - 4s 88us/step - loss: 0.0078 - acc: 0.9973 - val_loss: 0.0997 - val_acc: 0.9803\n",
            "Epoch 10/30\n",
            "48000/48000 [==============================] - 4s 88us/step - loss: 0.0047 - acc: 0.9984 - val_loss: 0.1014 - val_acc: 0.9803\n",
            "Epoch 11/30\n",
            "48000/48000 [==============================] - 4s 85us/step - loss: 0.0043 - acc: 0.9988 - val_loss: 0.1145 - val_acc: 0.9792\n",
            "Epoch 12/30\n",
            "24000/48000 [==============>...............] - ETA: 2s - loss: 0.0070 - acc: 0.9982"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "48000/48000 [==============================] - 4s 90us/step - loss: 0.0056 - acc: 0.9984 - val_loss: 0.1207 - val_acc: 0.9793\n",
            "Epoch 13/30\n",
            "48000/48000 [==============================] - 4s 86us/step - loss: 0.0042 - acc: 0.9985 - val_loss: 0.0962 - val_acc: 0.9810\n",
            "Epoch 14/30\n",
            "48000/48000 [==============================] - 4s 87us/step - loss: 0.0043 - acc: 0.9986 - val_loss: 0.1255 - val_acc: 0.9778\n",
            "Epoch 15/30\n",
            "48000/48000 [==============================] - 4s 89us/step - loss: 0.0020 - acc: 0.9994 - val_loss: 0.1006 - val_acc: 0.9822\n",
            "Epoch 16/30\n",
            "27000/48000 [===============>..............] - ETA: 1s - loss: 8.0114e-04 - acc: 0.9999"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "48000/48000 [==============================] - 4s 88us/step - loss: 6.2554e-04 - acc: 0.9999 - val_loss: 0.1028 - val_acc: 0.9828\n",
            "Epoch 17/30\n",
            "48000/48000 [==============================] - 4s 87us/step - loss: 7.7500e-05 - acc: 1.0000 - val_loss: 0.1057 - val_acc: 0.9828\n",
            "Epoch 18/30\n",
            "48000/48000 [==============================] - 4s 86us/step - loss: 2.0604e-05 - acc: 1.0000 - val_loss: 0.1077 - val_acc: 0.9828\n",
            "Epoch 19/30\n",
            "48000/48000 [==============================] - 4s 87us/step - loss: 1.3352e-05 - acc: 1.0000 - val_loss: 0.1115 - val_acc: 0.9830\n",
            "Epoch 20/30\n",
            "25200/48000 [==============>...............] - ETA: 1s - loss: 9.2159e-06 - acc: 1.0000"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "48000/48000 [==============================] - 4s 85us/step - loss: 8.1608e-06 - acc: 1.0000 - val_loss: 0.1158 - val_acc: 0.9832\n",
            "Epoch 21/30\n",
            "48000/48000 [==============================] - 4s 88us/step - loss: 5.1600e-06 - acc: 1.0000 - val_loss: 0.1196 - val_acc: 0.9831\n",
            "Epoch 22/30\n",
            "48000/48000 [==============================] - 4s 88us/step - loss: 3.5717e-06 - acc: 1.0000 - val_loss: 0.1224 - val_acc: 0.9833\n",
            "Epoch 23/30\n",
            "48000/48000 [==============================] - 4s 86us/step - loss: 2.6800e-06 - acc: 1.0000 - val_loss: 0.1247 - val_acc: 0.9833\n",
            "Epoch 24/30\n",
            "23000/48000 [=============>................] - ETA: 1s - loss: 2.0880e-06 - acc: 1.0000"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "48000/48000 [==============================] - 4s 85us/step - loss: 2.1315e-06 - acc: 1.0000 - val_loss: 0.1266 - val_acc: 0.9833\n",
            "Epoch 25/30\n",
            "48000/48000 [==============================] - 4s 86us/step - loss: 1.7541e-06 - acc: 1.0000 - val_loss: 0.1281 - val_acc: 0.9833\n",
            "Epoch 26/30\n",
            "48000/48000 [==============================] - 4s 85us/step - loss: 1.4878e-06 - acc: 1.0000 - val_loss: 0.1295 - val_acc: 0.9832\n",
            "Epoch 27/30\n",
            "48000/48000 [==============================] - 4s 84us/step - loss: 1.2798e-06 - acc: 1.0000 - val_loss: 0.1305 - val_acc: 0.9832\n",
            "Epoch 28/30\n",
            "25200/48000 [==============>...............] - ETA: 1s - loss: 1.0388e-06 - acc: 1.0000"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "48000/48000 [==============================] - 4s 86us/step - loss: 1.1199e-06 - acc: 1.0000 - val_loss: 0.1314 - val_acc: 0.9833\n",
            "Epoch 29/30\n",
            "48000/48000 [==============================] - 4s 89us/step - loss: 9.9564e-07 - acc: 1.0000 - val_loss: 0.1323 - val_acc: 0.9834\n",
            "Epoch 30/30\n",
            "48000/48000 [==============================] - 4s 85us/step - loss: 8.9254e-07 - acc: 1.0000 - val_loss: 0.1331 - val_acc: 0.9834\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3dd2e90630>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "qlka9aQkD4Nl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now we should evaluate the model on the test set"
      ]
    },
    {
      "metadata": {
        "id": "vGjhPdAbD7wB",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "78000d9f-fd82-4442-a3a1-faae0262d870",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1530806583605,
          "user_tz": -120,
          "elapsed": 743,
          "user": {
            "displayName": "Abd El Rhman ElMoghazy",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "112798608963931725749"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "print (\"Test Accuracy when evaluated on the X_test and the y test = %f\"% (model.evaluate(x_test, y_test, batch_size=128)[1]*100), \"%\" )"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 0s 30us/step\n",
            "Test Accuracy when evaluated on the X_test and the y test = 98.530000 %\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}